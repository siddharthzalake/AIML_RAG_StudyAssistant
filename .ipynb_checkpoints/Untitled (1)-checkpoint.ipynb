{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b687e01f-8f50-44e3-b39f-f0f6ce71b203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages\\google\\api_core\\_python_version_support.py:275: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\kalpa\\AppData\\Local\\Temp\\ipykernel_13880\\774337950.py:2: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401d0ed6-b48f-4de9-aa28-70f3436d615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-genai\n",
      "  Downloading google_genai-1.64.0-py3-none-any.whl.metadata (53 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-genai) (4.12.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.49.0.dev0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-genai) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-genai) (8.5.0)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-genai) (4.15.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-genai) (1.9.0)\n",
      "Collecting sniffio (from google-genai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: aiohttp>=3.10.11 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-genai) (3.13.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (46.0.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.6.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp>=3.10.11->google-genai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp>=3.10.11->google-genai) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp>=3.10.11->google-genai) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp>=3.10.11->google-genai) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp>=3.10.11->google-genai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp>=3.10.11->google-genai) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp>=3.10.11->google-genai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from aiohttp>=3.10.11->google-genai) (1.22.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\kalpa\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.6.2)\n",
      "Downloading google_genai-1.64.0-py3-none-any.whl (728 kB)\n",
      "   ---------------------------------------- 0.0/728.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/728.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/728.8 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/728.8 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/728.8 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/728.8 kB ? eta -:--:--\n",
      "   --------------------------- ---------- 524.3/728.8 kB 441.3 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 524.3/728.8 kB 441.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 728.8/728.8 kB 474.3 kB/s  0:00:01\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: websockets, sniffio, google-genai\n",
      "\n",
      "  Attempting uninstall: websockets\n",
      "\n",
      "    Found existing installation: websockets 16.0\n",
      "\n",
      "    Uninstalling websockets-16.0:\n",
      "\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "      Successfully uninstalled websockets-16.0\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ------------- -------------------------- 1/3 [sniffio]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   -------------------------- ------------- 2/3 [google-genai]\n",
      "   ---------------------------------------- 3/3 [google-genai]\n",
      "\n",
      "Successfully installed google-genai-1.64.0 sniffio-1.3.1 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939b58af-b582-4677-8923-1dae3cd042bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71359447-2d4a-4bb4-9d3d-c9ffd640fc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini ready\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyCPayHQbhaq4yLQr01tqx6suRIe3_cduFI\")\n",
    "\n",
    "print(\"Gemini ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c5763a-ad0b-45d1-bc18-fd0a6d961f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages loaded: 178\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "data_folder = \"data\"\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    \n",
    "    if file.endswith(\".pdf\"):\n",
    "        \n",
    "        loader = PyPDFLoader(os.path.join(data_folder, file))\n",
    "        \n",
    "        documents.extend(loader.load())\n",
    "\n",
    "print(\"Total pages loaded:\", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8873bd44-b3cb-4a0b-84af-910c237a0ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created: 898\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Chunks created:\", len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f776119c-1c92-465d-bf02-c2e069881712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalpa\\AppData\\Local\\Temp\\ipykernel_13880\\1839467482.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedding = SentenceTransformerEmbeddings(\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 151.87it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding ready\n"
     ]
    }
   ],
   "source": [
    "embedding = SentenceTransformerEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"Embedding ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd8ceecd-c73e-4dcc-8346-4b4131435604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB ready\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embedding,\n",
    "    persist_directory=\"./db\"\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "print(\"Vector DB ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08215826-a783-435e-8d93-fe6d6a117430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_dbms_assistant(question):\n",
    "\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a DBMS expert assistant.\n",
    "\n",
    "    Answer using the context below.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f0c5303-8586-4370-99b8-37bb09cf7994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database normalization is the process of organizing the attributes of the database to reduce or eliminate data redundancy (having the same data but at different places).\n",
      "\n",
      "It is crucial because data redundancy unnecessarily increases the size of the database and can lead to inconsistency problems during insert, delete, and update operations. Normalization helps to eliminate these anomalies and improve the overall quality and design of the database.\n",
      "\n",
      "According to E.F.Codd, the inventor of the Relational Database, the goals of normalization include:\n",
      "*   Vacating all repeated data from the database.\n",
      "*   Removing undesirable deletion, insertion, and update anomalies.\n",
      "*   Making a proper and useful relationship between tables.\n",
      "\n",
      "By breaking down complex data structures into simpler tables, normalization makes it easier to manage, update, and retrieve data, leading to an improved and more flexible database design.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is normalization in DBMS?\"\n",
    "\n",
    "answer = ask_dbms_assistant(question)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bcacb3f-72b0-423c-a285-89800ce22605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large chunks created: 472\n"
     ]
    }
   ],
   "source": [
    "# Create large chunks (Experiment 1)\n",
    "\n",
    "text_splitter_large = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "chunks_large = text_splitter_large.split_documents(documents)\n",
    "\n",
    "print(\"Large chunks created:\", len(chunks_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8278d5e-5941-4949-92b6-8447d305f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large chunk vector DB ready\n"
     ]
    }
   ],
   "source": [
    "# Create vector database with large chunks\n",
    "\n",
    "vectorstore_large = Chroma.from_documents(\n",
    "    chunks_large,\n",
    "    embedding,\n",
    "    persist_directory=\"./db_large\"\n",
    ")\n",
    "\n",
    "retriever_large = vectorstore_large.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "print(\"Large chunk vector DB ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39235f65-fccb-412b-b666-9b5857050c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_large_chunks(question):\n",
    "\n",
    "    docs = retriever_large.invoke(question)\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Answer using context below.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffe78e6c-4e39-4bb5-a182-f2bab48d8fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: What is normalization?\n",
      "\n",
      "Fixed chunk answer:\n",
      "Database normalization is the process of organizing the attributes of the database to reduce or eliminate data redundancy (having the same data but at different places). It helps to eliminate anomalies, improve the overall quality of the database, ensure data consistency, and simplify data management.\n",
      "\n",
      "Large chunk answer:\n",
      "Normalization involves organizing data into tables and applying rules to ensure data is stored in a consistent and efficient manner. By reducing data redundancy and ensuring data integrity, it helps to eliminate anomalies and improve the overall quality of the database.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "QUESTION: What is primary key?\n",
      "\n",
      "Fixed chunk answer:\n",
      "Based on the context, a primary key is a proper subset chosen from super keys that can be used to identify unique rows (tuples) in a given relationship. The context also states that \"Such keys\" (which can be used as a primary key) are known as Candidate keys. If a primary key uses a combination of two or more attributes, it is called a Composite key.\n",
      "\n",
      "Large chunk answer:\n",
      "The provided context states that a primary key can be chosen from a proper subset of superkeys. It mentions, \"Out of these super keys, we can always choose a proper subset among these that can be used as a primary key. Such keys are known as Candidate keys.\"\n",
      "\n",
      "However, the context does not explicitly provide a direct definition of what a primary key *is* beyond its relationship to superkeys and candidate keys.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "QUESTION: Explain ACID properties\n",
      "\n",
      "Fixed chunk answer:\n",
      "ACID properties are the four key characteristics that define the reliability and consistency of a transaction in a Database Management System (DBMS). The acronym ACID stands for Atomicity, Consistency, Isolation, and Durability.\n",
      "\n",
      "Here is a brief description of each:\n",
      "*   **Atomicity:** Ensures that a transaction is treated as a single, indivisible unit of work. This means either all changes within a transaction are successfully committed to the database, or none of them are. If any part of the transaction fails, the entire transaction is rolled back to its original state.\n",
      "*   **Consistency:** Ensures that a transaction brings the database from one valid state to another. All data must be valid according to all defined rules (constraints, triggers, cascades, etc.). If a transaction violates any of these rules, it is rolled back.\n",
      "*   **Isolation:** Ensures that concurrent transactions do not interfere with each other. Each transaction appears to be executed in isolation, meaning the intermediate state of one transaction is not visible to other concurrent transactions.\n",
      "*   **Durability:** Ensures that once a transaction has been committed, its changes are permanently stored and will survive any subsequent system failures (e.g., power outages, crashes).\n",
      "\n",
      "Large chunk answer:\n",
      "ACID properties are four key characteristics that define the reliability and consistency of a transaction in a Database Management System (DBMS). The acronym ACID stands for:\n",
      "\n",
      "*   **Atomicity:** Ensures that a transaction is treated as a single, indivisible unit of work. Either all operations within the transaction are completed successfully, or none of them are. If any part of the transaction fails, the entire transaction is rolled back to its original state, ensuring data consistency and integrity.\n",
      "*   **Consistency:** Ensures that a transaction takes the database from one consistent state to another consistent state. The database is consistent both before and after the transaction executes, and constraints (like unique and foreign keys) must be maintained.\n",
      "*   **Isolation:** While not detailed in a dedicated bullet, ACID properties help manage multiple concurrent transactions by preventing interference between them, ensuring that transactions operate independently from other operations.\n",
      "*   **Durability:** While not detailed in a dedicated bullet, ACID properties ensure that updates made by a transaction are durably stored. This means any changes to the database are permanent and cannot be lost, and helps with data recovery in case of system failure.\n",
      "\n",
      "Overall, ACID properties provide a framework for ensuring data consistency, integrity, and reliability in DBMS, making them reliable and efficient for managing data.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "\"What is normalization?\",\n",
    "\"What is primary key?\",\n",
    "\"Explain ACID properties\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "\n",
    "    print(\"\\nQUESTION:\", q)\n",
    "\n",
    "    print(\"\\nFixed chunk answer:\")\n",
    "    print(ask_dbms_assistant(q))\n",
    "\n",
    "    print(\"\\nLarge chunk answer:\")\n",
    "    print(ask_large_chunks(q))\n",
    "\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c402a6-8455-465b-97e5-883f635689b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 1: Comparison of Chunking Strategies\n",
    "\n",
    "In this experiment, two different chunk sizes were used to divide the DBMS notes:\n",
    "\n",
    "- Small chunks (500 characters with overlap)\n",
    "- Large chunks (1000 characters with overlap)\n",
    "\n",
    "The small chunk method created 898 chunks, while the large chunk method created 472 chunks.\n",
    "\n",
    "### Observations\n",
    "\n",
    "When testing both methods with DBMS questions, I observed that the small chunk method generally provided more accurate and detailed answers. This is because smaller chunks allow the system to retrieve very specific and relevant pieces of information.\n",
    "\n",
    "On the other hand, the large chunk method sometimes provided shorter or incomplete answers. This may happen because larger chunks contain more mixed information, which can make it harder for the retriever to select the most precise content.\n",
    "\n",
    "For example, in the question about the primary key, the small chunk method provided a clearer explanation, while the large chunk method returned a less complete answer.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Based on these observations, the small chunk strategy performed better for DBMS notes. Smaller chunks improve retrieval precision and help the model generate more accurate answers.\n",
    "\n",
    "However, large chunks can still be useful when concepts require broader context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bb746dd-3586-43e9-9ad3-7079d7fa6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_improved_prompt(question):\n",
    "\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in DBMS.\n",
    "\n",
    "    Explain the answer clearly in simple words.\n",
    "\n",
    "    Give example if possible.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Provide detailed explanation:\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f87bec7-6388-4aab-af01-e450d04620bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Prompt Answer:\n",
      "\n",
      "A transaction is a collection of operations that performs a single logical function in a database application. It is also defined as a single logical unit of work that accesses and possibly modifies the contents of a database. A set of logically related operations is known as a transaction.\n",
      "\n",
      "\n",
      "Improved Prompt Answer:\n",
      "\n",
      "As an expert in DBMS, let me explain what a transaction is in simple words, drawing from the context you've provided.\n",
      "\n",
      "---\n",
      "\n",
      "### What is a Transaction in DBMS?\n",
      "\n",
      "In the world of Database Management Systems (DBMS), a **transaction** is a fundamental concept that ensures the reliability and integrity of your data, especially when multiple operations or users are involved.\n",
      "\n",
      "Think of it as a **single, indivisible unit of work** that performs a specific logical function in the database. This unit of work comprises a collection of one or more database operations (like reading, inserting, updating, or deleting data) that are *logically related* and must either all succeed together or all fail together.\n",
      "\n",
      "**Here's a breakdown:**\n",
      "\n",
      "1.  **A Single Logical Function:**\n",
      "    *   A transaction isn't just a random bunch of database commands. It's a series of operations that collectively achieve one complete and meaningful task.\n",
      "    *   **Example:** Transferring money from one bank account to another is a single logical function. It involves debiting one account AND crediting another.\n",
      "\n",
      "2.  **All or Nothing (Atomicity):**\n",
      "    *   This is the core idea. A transaction is treated as an \"all or nothing\" proposition. Either every operation within it completes successfully and permanently changes the database, or if even one operation fails (or there's a system crash), then *none* of the operations take effect, and the database is rolled back to its state *before* the transaction began.\n",
      "    *   This \"all or nothing\" property is called **Atomicity**, which is one of the famous ACID properties.\n",
      "\n",
      "3.  **Maintains Consistency:**\n",
      "    *   The primary goal of a transaction is to move the database from one **consistent state** to another. A consistent state means the database adheres to all its rules and constraints (e.g., account balances shouldn't be negative, total money in the system should remain the same after a transfer).\n",
      "    *   A transaction starts when the database is consistent, performs its operations, and if successful, leaves the database in a new, consistent state. If it fails, it ensures the database returns to its *original* consistent state.\n",
      "\n",
      "4.  **Involves Read and Write Operations:**\n",
      "    *   Transactions interact with the database by reading existing data and potentially writing (inserting, updating, or deleting) new or modified data.\n",
      "\n",
      "5.  **Crucial for Concurrency and Recovery:**\n",
      "    *   When multiple users or programs try to access and modify the same data simultaneously (**concurrency**), transactions prevent chaos and ensure that each operation sees a consistent view of the data.\n",
      "    *   In case of system failures (like a power outage or software crash), transactions allow the database to recover to a consistent state, preventing data loss or corruption.\n",
      "\n",
      "### The ACID Properties: The Guardians of Transactions\n",
      "\n",
      "To achieve its purpose, every transaction must adhere to the **ACID properties**:\n",
      "\n",
      "*   **Atomicity:** (As explained above) All operations within a transaction either complete successfully, or none do. It's indivisible.\n",
      "*   **Consistency:** A transaction brings the database from one valid, consistent state to another valid, consistent state.\n",
      "*   **Isolation:** When multiple transactions are running concurrently, each transaction should appear to execute independently, without interfering with others. It's as if they are running one after another.\n",
      "*   **Durability:** Once a transaction is successfully completed (committed), its changes are permanent and will survive even in the event of system failures (like power loss).\n",
      "\n",
      "### Example: Bank Account Transfer\n",
      "\n",
      "Let's illustrate with the classic example of transferring money between two bank accounts.\n",
      "\n",
      "**Scenario:** You want to transfer $100 from your Savings Account (Account_A) to your Checking Account (Account_B).\n",
      "\n",
      "**Without Transactions:**\n",
      "If you just did two separate operations:\n",
      "1.  Debit $100 from Account_A.\n",
      "2.  Credit $100 to Account_B.\n",
      "What if a power outage happens *after* step 1 but *before* step 2?\n",
      "*   Your Savings Account is debited ($100 gone).\n",
      "*   Your Checking Account is *not* credited ($100 never arrived).\n",
      "*   Result: $100 has vanished from the system, and the database is in an inconsistent state! This is unacceptable.\n",
      "\n",
      "**With Transactions (The Correct Way):**\n",
      "\n",
      "The entire transfer process is wrapped in a single transaction:\n",
      "\n",
      "1.  **START TRANSACTION;**\n",
      "2.  **READ** Account_A_balance (e.g., $500)\n",
      "3.  **UPDATE** Account_A SET balance = balance - 100; (Account_A becomes $400)\n",
      "4.  **READ** Account_B_balance (e.g., $200)\n",
      "5.  **UPDATE** Account_B SET balance = balance + 100; (Account_B becomes $300)\n",
      "6.  **COMMIT;** (If everything went well)\n",
      "\n",
      "**What happens:**\n",
      "\n",
      "*   **Success:** If all steps complete successfully, the `COMMIT` command makes the changes permanent. Account_A is $400, Account_B is $300. The total money in the bank remains the same, and the database is consistent.\n",
      "*   **Failure (e.g., power outage after step 3 but before step 5):** The database system detects that the transaction was not `COMMITTED`. It will automatically perform a **ROLLBACK**.\n",
      "    *   All changes made by the incomplete transaction are undone.\n",
      "    *   Account_A will revert to its original $500.\n",
      "    *   Account_B will remain its original $200.\n",
      "    *   The database is returned to its state *before* the transfer attempt, maintaining consistency. No money is lost or created.\n",
      "\n",
      "In essence, transactions are the bedrock of reliable and robust database systems, ensuring that your data remains correct and safe, no matter what operations are performed or what unexpected issues arise.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is transaction in DBMS?\"\n",
    "\n",
    "print(\"Basic Prompt Answer:\\n\")\n",
    "print(ask_dbms_assistant(question))\n",
    "\n",
    "print(\"\\n\\nImproved Prompt Answer:\\n\")\n",
    "print(ask_improved_prompt(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a321736-e18b-4d53-bfb6-291cc729d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 2: Prompt Engineering Comparison\n",
    "\n",
    "In this experiment, I tested how different prompt styles affect the quality of answers generated by the system.\n",
    "\n",
    "Two prompts were used:\n",
    "\n",
    "1. Basic prompt – simple instruction to answer using the context\n",
    "2. Improved prompt – detailed instruction asking the model to explain clearly and provide examples\n",
    "\n",
    "### Observations\n",
    "\n",
    "The basic prompt generated correct answers, but the explanations were often short and lacked detail.\n",
    "\n",
    "The improved prompt generated more detailed, clearer, and easier-to-understand answers. The model also explained concepts in a more structured way, similar to how a teacher explains.\n",
    "\n",
    "For example, when asked about normalization, the improved prompt provided a better explanation and included useful details.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Prompt design has a significant impact on answer quality. A well-written prompt improves clarity, completeness, and usefulness of the generated answers.\n",
    "\n",
    "This shows that prompt engineering is an important part of building effective RAG systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
